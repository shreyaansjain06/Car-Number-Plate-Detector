{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport h5py\nimport numpy as np\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom keras.optimizers import RMSprop\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"img=cv2.imread('../input/mosaicps2/dataset/0/0_1.jpg')\n","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_dir='../input/mosaicps2/dataset'","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainDataGen = ImageDataGenerator(rescale = 1.0/255)","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainGenerator = trainDataGen.flow_from_directory(\ntrain_dir,\ntarget_size = (28,28),\nbatch_size = 36,\ncolor_mode = \"grayscale\",\nclass_mode = \"categorical\")","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Found 36576 images belonging to 36 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 #activation ='relu'))\n#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 #activation ='relu'))\n#model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n#model.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(36, activation = \"softmax\"))","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_8 (Conv2D)            (None, 28, 28, 32)        832       \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 28, 28, 32)        25632     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 14, 14, 64)        18496     \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 14, 14, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               1606144   \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 36)                18468     \n=================================================================\nTotal params: 1,706,500\nTrainable params: 1,706,500\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"history=model.fit_generator(trainGenerator,verbose=1,epochs=10,steps_per_epoch=(1016*36) // 100)","metadata":{"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/10\n365/365 [==============================] - 10s 25ms/step - loss: 1.7102 - accuracy: 0.5392\nEpoch 2/10\n365/365 [==============================] - 9s 25ms/step - loss: 0.3861 - accuracy: 0.8922\nEpoch 3/10\n365/365 [==============================] - 10s 26ms/step - loss: 0.2618 - accuracy: 0.9205\nEpoch 4/10\n365/365 [==============================] - 9s 25ms/step - loss: 0.2315 - accuracy: 0.9341\nEpoch 5/10\n365/365 [==============================] - 10s 29ms/step - loss: 0.2106 - accuracy: 0.9373\nEpoch 6/10\n365/365 [==============================] - 10s 27ms/step - loss: 0.1868 - accuracy: 0.9485\nEpoch 7/10\n365/365 [==============================] - 9s 26ms/step - loss: 0.1639 - accuracy: 0.9518\nEpoch 8/10\n365/365 [==============================] - 9s 25ms/step - loss: 0.1677 - accuracy: 0.9523\nEpoch 9/10\n365/365 [==============================] - 9s 26ms/step - loss: 0.1577 - accuracy: 0.9558\nEpoch 10/10\n365/365 [==============================] - 9s 26ms/step - loss: 0.1418 - accuracy: 0.9564\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"Model_plate.h5\")","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
